{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 参考\n",
    "\n",
    "* [参考](https://www.sohu.com/a/241338315_787107)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 图片输入到计算机中是什么形式的?\n",
    "\n",
    "* 彩色图像由RGB三个通道,每个通道内的点都由(0-255)中某个值表示.假设一张900\\*600的彩色图片,计算机里就会用(900\\*600\\*3)的数组表示\n",
    "    * ![](http://5b0988e595225.cdn.sohucs.com/images/20180715/7b0a8af806b940fd86c62e3884f770bb.jpeg)\n",
    "    * 注意上面图片仅仅表示RGB其中一个通道,如果表示三个通道,则需要由三张图片前后叠加\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 什么是卷积?\n",
    "\n",
    "* 卷积过程就是用一个小矩阵(经常是方针)去和上面数组中相同大小位置进行乘机并累加.将结果放到一个新的矩阵中相应位置.\n",
    "    * ![](http://5b0988e595225.cdn.sohucs.com/images/20180715/54ea427933f94b588a087bbd42e0c6b9.gif)\n",
    "\n",
    "* 卷积必然涉及到卷积核 convolution\n",
    "    * 我们训练神经网络的目的就是为了寻找卷积核中每个值(神经元参数)\n",
    "    * 卷积核的步长指卷积核每次移动的格子数量,有横向和纵向两个方向\n",
    "    * 卷积核相当于一个过滤器,将原始图像进行特征提取\n",
    "\n",
    "* Padding\n",
    "    * 卷积操作之后维度会变少,得到的矩阵比原来的矩阵小,所以进行padding,在原始矩阵外部补一层0\n",
    "    \n",
    "* 池化pooling\n",
    "    * 卷积操作后我们提取了很多特征信息，相邻区域有相似特征信息，可以相互替代的，如果全部保留这些特征信息就会有信息冗余，增加了计算难度，这时候池化就相当于降维操作。池化是在一个小矩阵区域内，取该区域的最大值或平均值来代替该区域，该小矩阵的大小可以在搭建网络的时候自己设置。小矩阵也是从左上角扫到右下角。如下图\n",
    "    * ![](http://5b0988e595225.cdn.sohucs.com/images/20180715/f70b4f66555c4ace8756c3eb59fc10f9.gif)\n",
    "\n",
    "* Flatten\n",
    "    * Flatten 是指将多维的矩阵拉开，变成一维向量来表示。\n",
    "\n",
    "* 全连接层 Dense\n",
    "    * 对n-1层和n层而言，n-1层的任意一个节点，都和第n层所有节点有连接。即第n层的每个节点在进行计算的时候，激活函数的输入是n-1层所有节点的加权。像下面的中间层就是全连接方式。\n",
    "    * ![](http://5b0988e595225.cdn.sohucs.com/images/20180715/5cea91f9793a47da8928ae5a83037ddb.jpeg)\n",
    "    \n",
    "* Dropout\n",
    "    * dropout是指在网络的训练过程中，按照一定的概率将网络中的神经元丢弃，这样有效防止过拟合。\n",
    "    \n",
    "* SGD \n",
    "    * 随机梯度下降法训练参数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG16\n",
    "\n",
    "* ![](http://5b0988e595225.cdn.sohucs.com/images/20180715/9bb7534dc4a44496a995dc5c30cac0cd.jpeg)\n",
    "\n",
    "* 从左至右，一张彩色图片输入到网络，白色框是卷积层，红色是池化，蓝色是全连接层，棕色框是预测层。预测层的作用是将全连接层输出的信息转化为相应的类别概率，而起到分类作用。可以看到 VGG16 是13个卷积层+3个全连接层叠加而成。\n",
    "\n",
    "* 注意彩色图片是三通道\n",
    "    * 对于RGB三通道而言，就是在R,G,B三个通道上分别使用对应的每个通道上的kernel_size*kernel_size大小的核去卷积每个通道上的W*H的图片，然后将三个通道卷积得到的输出相加，得到M个二维卷积输出结果，在有padding的情况下，能保持输出图片大小和原来的一样\n",
    "    * 这里是让每个卷积核与三通道每个图片对应位置进行乘机叠加后,再将三个叠加后的值再次叠加成为一个值!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
