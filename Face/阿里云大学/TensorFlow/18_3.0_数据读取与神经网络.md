
# 3 数据读取与神经网络

三种获取数据：
1. QueueRunner 基于队列的输入管道，从TensorFlow图形开头的文件中读取数据。
2. Feeding 运行每一步时，python代码提供数据
3. 预加载数据 张量包含所有数据。

### 3.1.1 文件读取流程
多任务 + 队列

filename -- random shuffle --> filename Queue


- 第一阶段 构建文件名队列
- 第二阶段 读取文件和解码
- 第三阶段 批处理队列
- 第四阶段 启动线程
  
【注】这些操作需要启动运行这些队列操作的**线程**，以便我们在进行文件读取的过程中能够顺利进行入队出队操作。

1. 构造文件名队列
    将需要读取的文件的文件名放入文件名队列。
    ```python
    file_queue = tf.train.string_input_producer(string_tensor, shuffle=True)
    ```
    - string_tensor 含有文件名+路径的1阶张量。传列表即可，会自动 转成张量。
    - num_epochs 过几遍数据，默认为无限遍数据
    - return 文件队列

2. 读取与解码
   从队列中读取文件内容，并进行解码操作。
   - 1) 读取文件内容
     - 阅读器每次只读取一个样本。都有一个read()方法，key, value = 读取器.read(file_queue)
       - 文本： 
         - 读取：`tf.TextLineReader` 默认按行读取，return 阅读器实例。
         - 解码：tf.decode_csv()
       - 图片： 
         - 读取：`tf.WholeFileReader` 用于读取图片文件
         - 解码：tf.image_decode_jpeg(contents)tf.image_decode_png(contents)
       - 二进制： 
         - 读取：`tf.FixedLengthRecordReader(record_bytes)` 二进制文件。
           - 要读取每个记录是固定量字节的二进制文件
           - record_bytes 整型，指定每次读取的字节数
         - 解码：tf.decode_raw 解码二进制文件内容。
       - TFRecord：  `tf.TFRecordReader` 读取TFRecords文件。
   - 2) 内容解码
3. 批处理
   解码之后，可以直接获取默认的一个样本内容了。但如果想要获取多个样本，需要加入到新的队列进行批处理。
   - tf.train.batch(tensors, batch_size, num_threads=1, capacity=32, name=None) 读取指定大小的张量
     - tensors 包含张量的列表
     - batch_sizes 从队列中读取的批处理大小 
     - num_threads 进入队列的线程数
     - capacity 队列中元素的最大数量
     - return tensors
   - tf.train.shuffle_batch()



### 3.1.2 线程操作
以上用到的队列都是 tf.train.QueueRunner 对象。

每个QueueRunner负责一个阶段，tf.train.start_queue_runners 函数会要求图中的每个QueueRunner启动它的运行队列操作的线程。（这些操作都需要在会话中开启）

- tf.train.start_queue_runners(sess=None, coord=None) 收集图中所有的队列线程，默认同时启动线程
  - sess 所有的会话
  - coord 线程协调器
  - return : 返回所有线程
- tf.train.Coordinate() 线程协调员，对线程进行管理和协调。
  - request_stop() 请求停止
  - should_stop() 询问是否结束
  - join(threads=None, stop_grace_period_secs=120) 回收线程
  - return : 线程协调员实例。
