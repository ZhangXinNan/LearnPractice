LiDAR是感知主角，但是成本太高，所以用成本低的摄像头去承担更多感知任务。
# 1 无人驾驶的感知
广义的视觉：超声波雷达（倒车雷达）、毫米波雷达、LiDAR、摄像头。
毫米波雷达、激光雷达 中长距测距和环境感知。

# 2 KITTI数据集
激光雷达提供的数据作为ground truch。


# 3 CV帮助无人车解决的问题
交通标志和信号灯的识别、高速公路车道检测和定位。
物体的识别与跟踪
车辆本身的定位
# 4 Optical Flow 和 立体视觉
Optical Flow 是图片序列或者视频中像素级的密集对应关系。单个摄像头连续时刻。
立体视觉是两个或更多的视角得到的图像中建立对应关系。多个摄像头同一时刻。
**Siamese网络**，用一个内积代替拼接层，把处理一对图片的时间从一分钟降到一秒。




# 5 物体的识别与追踪
从像素层面的颜色、偏移、距离信息到物体层面的空间位置和运动轨迹，是无人车视觉感知系统的重要功能。无人车的感知系统需要实时识别和跟踪多个运动目标（Multi-object tracking, MOT）。
ICCV2015会议，斯坦福大学研究者发表了基于马尔可夫决策过程（MDP）的MOT算法。

# 6 视觉里程计算法
## 6.1 基于拓扑和地标的算法。把所有地标预告建立精准拓扑图，当无人车监测到某个地标时，今天晚大致推断出自己所在的位置。
## 6.2 基于几何的视觉里程计算法。在定位的同时拓展地图。
1. 单目：无法推算观察到的物体大小。
2. 双目：通过左右图triangulation计算出特征点深度，然后从深度信息中推算出物体的大小。

# 7 结论
