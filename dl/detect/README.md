目标检测
--------

[目标检测的入门与进阶（上篇）](https://mp.weixin.qq.com/s/R4NJp5ZL2-2T-bnkfFO8bg)
[目标检测入门于进阶（下篇）](https://mp.weixin.qq.com/s/73hD4Oq7xo3YkrDVy53Lyg)
[【深度学习】目标检测算法总结(R-CNN Fast R-CNN Faster R-CNN FPN YOLO SSD RetinaNet)](https://www.cnblogs.com/guoyaohua/p/8994246.html)


# 一、基于候选区域的目标检测器
## 1.1  滑动窗口检测器
## 1.2  选择性搜索
候选区域方法（region proposal method）创建目标检测的感兴趣区域（ROI）
## 1.3  R-CNN

## 1.4  Fast R-CNN
R-CNN很多卷积运算是重复的。

(1) Fast R-CNN 使用特征提取器（CNN）先提取整个图像的特征，而不是从头开始对每个图像块提取多次。
(2) 将创建候选区域的方法直接应用到提取到的特征图上。
(3) 使用 ROI 池化将特征图块转换为固定的大小，并馈送到全连接层进行分类和定位。因为 Fast-RCNN 不会重复提取特征，因此它能显著地减少处理时间。
Fast R-CNN 最重要的一点就是包含特征提取器、分类器和边界框回归器在内的整个网络能通过多任务损失函数进行端到端的训练，这种多任务损失即结合了分类损失和定位损失的方法，大大提升了模型准确度。

### ROI池化

## 1.5  Faster R-CNN
Faster R-CNN 采用与 Fast R-CNN 相同的设计，只是它用内部深层网络代替了候选区域方法。新的候选区域网络（RPN）在生成 ROI 时效率更高，并且以每幅图像 10 毫秒的速度运行。

### 候选区域网络(RPN)
候选区域网络（RPN）将第一个卷积网络的输出特征图作为输入。它在特征图上滑动一个 3×3 的卷积核，以使用卷积网络（如下所示的 ZF 网络）构建与类别无关的候选区域。

对于特征图中的每一个位置，RPN 会做 k 次预测。因此，RPN 将输出 4×k 个坐标和每个位置上 2×k 个得分。下图展示了 8×8 的特征图，且有一个 3×3 的卷积核执行运算，它最后输出 8×8×3 个 ROI（其中 k=3）。下图（右）展示了单个位置的 3 个候选区域。


Faster R-CNN 不会创建随机边界框。相反，它会预测一些与左上角名为「锚点」的参考框相关的偏移量（如x、y）。我们限制这些偏移量的值，因此我们的猜想仍然类似于锚点。
Faster R-CNN 使用更多的锚点。它部署 9 个锚点框：3 个不同宽高比的 3 个不同大小的锚点框。每一个位置使用 9 个锚点，每个位置会生成 2×9 个 objectness 分数和 4×9 个坐标。

## 1.6  基于区域的全卷积神经网络（R-FCN）
R-FCN 通过减少每个 ROI 所需的工作量实现加速（去掉了全连接层）。上面基于区域的特征图与 ROI 是独立的，可以在每个 ROI 之外单独计算。剩下的工作就比较简单了，因此 R-FCN 的速度比 Faster R-CNN 快。

将得分图(Feature Map)和 ROI 映射到 vote 数组的过程叫作位置敏感 ROI 池化（position-sensitive ROI-pool）。该过程与前面讨论过的 ROI 池化非常接近。

## 1.7  R-CNN系列总结

# 二、单次目标检测器
## 2.1  单次检测器

## 2.2  SSD (Single Shot MultiBox Detector)
卷积层降低了空间维度和分辨率。因此上述模型仅可以检测较大的目标。为了解决该问题，我们从多个特征图上执行独立的目标检测。采用多尺度特征图独立检测。

## 2.3  YOLO


YOLOv3 使用了更加复杂的骨干网络来提取特征。DarkNet-53 主要由 3 × 3 和 1× 1 的卷积核以及类似 ResNet 中的跳过连接构成。相比 ResNet-152，DarkNet 有更低的 BFLOP（十亿次浮点数运算），但能以 2 倍的速度得到相同的分类准确率。
YOLOv3 还添加了特征金字塔，以更好地检测小目标。以下是不同检测器的准确率和速度的权衡。

### 特征金字塔网络（FPN）
特征金字塔网络（FPN）是一种旨在提高准确率和速度的特征提取器。它取代了检测器（如 Faster R-CNN）中的特征提取器，并生成更高质量的特征图金字塔。
FPN 由自下而上和自上而下路径组成。其中自下而上的路径是用于特征提取的常用卷积网络。空间分辨率自下而上地下降。当检测到更高层的结构，每层的语义值增加。
FPN 提供了一条自上而下的路径，从语义丰富的层构建高分辨率的层。
虽然该重建层的语义较强，但在经过所有的上采样和下采样之后，目标的位置不精确。在重建层和相应的特征图之间添加横向连接可以使位置侦测更加准确。

### FPN 结合 RPN

### FPN 结合 Fast R-CNN 或 Faster R-CNN

### Focal Loss（RetinaNet）
类别不平衡会损害性能。SSD 在训练期间重新采样目标类和背景类的比率，这样它就不会被图像背景淹没。Focal loss（FL）采用另一种方法来减少训练良好的类的损失。因此，只要该模型能够很好地检测背景，就可以减少其损失并重新增强对目标类的训练。我们从交叉熵损失 CE 开始，并添加一个权重来降低高可信度类的 CE。







