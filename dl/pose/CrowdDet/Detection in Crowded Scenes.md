Detection in Crowded Scenes: One Proposal, Multiple Predictions  
_________

# 0 Abstract

We propose a simple yet effective **proposal-based** object detector, aiming at detecting **highly-overlapped** instances in crowded scenes. The key of our approach is to let each proposal **predict a set of correlated instances** rather than a single one in previous proposal-based frameworks. Equipped with new techniques such as **EMD Loss** and **Set NMS**, our detector can effectively handle the difficulty of detecting highly overlapped objects. On a FPN-Res50 baseline, our detector can obtain 4.9% AP gains on challenging CrowdHuman dataset and 1.0% $MR^{-2}$ improvements on CityPersons dataset, without bells and whistles. Moreover, on less crowed datasets like COCO, our approach can still achieve moderate improvement, suggesting the proposed method is robust to crowdedness.    


# 1. Introduction

Proposal-based framework has been widely used in modern object detection systems [29, 11, 12, 20, 21, 24, 14, 4, 5, 2, 13, 28, 34, 33], both for one-stage [24, 28, 21, 10] and two/multi-stage [29, 20, 4, 5, 13, 2] methods. The paradigm in general has a two-step pipeline: first, generating overcomplete object proposals in handcraft (e.g. predefined anchors [28, 24, 21]) or learnable (e.g. RPNs [29, 20, 13]) manner; then, predicting a single instance corresponding to each proposal box with a confidence score and a refined location. To remove duplicate predictions, methods such as Non-maximum Suppression (NMS) are usually required for post-processing. 

 
Although proposal-based approaches have achieved state-of-the-art performances [13, 2, 20, 21] in popular datasets such as COCO [22] and PASCAL VOC [8], it is still very challenging for crowded detection in practice. Fig. 1 (a) shows a common failure case: the detector fails to predict instances heavily overlapped with others (indicated in dashed box). 


This kind of typical failure in crowded scenes is mainly ascribed to two reasons. First, highly overlapped instances (as well as their associated proposals) are likely to have very similar features. As a result, it is difficult for a detector to generate distinguishing prediction for each proposal respectively (illustration is show in Fig. 2 for a concrete example). Second, since instances may heavily overlap each other, the predictions are very likely to be mistakenly suppressed by NMS, as depicted in Fig. 1 (a). 


Previous works have tried to address this issue from different perspectives, such as sophisticated NMS [1, 16, 23, 18, 25, 17], new loss functions [44, 40], re-scoring [19], part-based detectors [44, 38, 46, 3]. However, as we will analyze later (Sec. 2), current works are either too complex or less effective for handing highly-overlapped cases, or degrading the performance of less-overlapped cases. 




In this paper, a new scheme is introduced to handle this difficulty: for each proposal box, instead of predicting a single instance, as usual, we suggest **predicting a set of instances** that might be highly overlapped, as described in Fig. 2. With this scheme, the predictions of nearby proposals are expected to infer the same set of instances, rather than distinguishing individuals, which is much easy to be learned. We also introduce several techniques in the new scheme. Firstly, a **EMD loss** is proposed to supervise the learning of instance set prediction. Secondly, **a new postprocessing method named Set NMS** is introduced to suppress the duplicates from different proposals, which aims at overcoming the drawbacks of naive NMS in crowd scenes. Lastly, an optional **refinement module (RM)** is designed to handle the potential false positives. 



Our method is simple and almost cost-free. It is applicable to all the proposal-based detectors such as [29, 20, 21, 13]. The major modification is adding a prediction branch, which only brings negligible extra cost. But the improvement is significant: on CrowdHuman [32] dataset, our method boosts the AP score by 4.5% (without refinement module) or 4.9% (with refinement module); in addition, the recall on crowded instances improves by 8.9%. More importantly, fewer false positive appears, suggested by the slightly improved $MR^{-2}$ index even without refinement module. Besides, on less crowded datasets, our method can still obtain moderate gains. For example, on CityPersons we achieve 0.9% and 1.0% improvements in AP and $MR^{-2}$ over the baseline; and on COCO, [22] it obtains 1.0% higher AP score. All experiments conducted on different datasets illustrate that our method can handle all scenes gracefully, regardless of the crowdedness.  


 
 # 2. Background
 
As mentioned in the introduction, the paradigm of proposal-based object detectors mainly involves two steps: the first step is proposal box generation, which could be achieved by Selective Search [12, 11], predefined/learnable anchors [29, 28, 24, 21, 41, 39, 45] or Region Proposal Networks (RPNs) [29, 20, 13, 4, 2], etc. The second step is instance prediction, i.e. predicting the refined detection results corresponding to each proposal box. We primarily focus on the second step in this paper. For instance prediction, current state-of-the-art object detection frameworks [29, 20, 21, 24, 28] usually attach a detection function to each proposal box, which is used to determine whether the proposal is associated to some ground truth instance; if true, further to predict the corresponding class label and the refined bounding box for the object. This mechanism implies that each proposal box corresponds to single ground truth (usually the one with the largest overlap to the proposal box). Therefore, the proposal boxes have to be over-completed to ensure every instance has a chance to be detected, which introduces many duplicates to the predictions. As a result, duplicate removal methods such as Non-Maximum Suppression (NMS) are necessary for those frameworks to filter out the duplicate results. Although the above paradigm seems to obtain outstanding results on some benchmarks such as COCO [22] and PASCAL VOC [8]. It suffers from missing detection in crowded scenarios due to post-processing methods, e.g. NMS. Fig. 1 (a) shows an example: people in the dashed boxes are suppressed by the nearby boxes mistakenly. Thus, several approaches or workarounds have been proposed to address this limitation, which can be categorized as follows: Advanced NMS. The effectiveness of na¨ıve NMS is based on the assumption that multiple instances rarely occur at the same location, which is no longer satisfied in the crowded scenes. Several improved NMS approaches have been proposed. For example, Soft-NMS [1] and Softer-NMS [16] suggest decaying the confidence score of the neighboring predictions for suppression rather than directly discard them. [30] employs Quadratic Binary Optimization to predict instances, taking advantage of the prior distribution of ground truth’s sizes. However, such heuristic variants of NMS are not always valid under different circumstances. Thus, more complex mechanisms may be introduced, for example, [18, 25] uses a neural network for more sophisticated and data-dependent duplicate removal. Although these methods raise the upper bound of na¨ı’ve NMS, the pipeline becomes much more complex and costly in computation. Other works such as [23, 17] propose to predict different NMS thresholds for different bounding boxes. As the major drawback, they need an extra structure for IoU/density estimation, which introduces more hyperparameters. Besides, it is still difficult to distinguish heavily overlapped boxes as in Fig 2 (a). Loss functions for crowded detection. A few previous works propose new loss functions to address the problem of crowded detection. For example, [43] proposes Aggregation Loss to enforce proposals to be close and locate compactly to the corresponding ground truth. [40] proposes Repulsion Loss, which introduces extra penalty to proposals intertwine with multiple ground truths. The quality of detections in crowded scenes is improved with the help of these loss functions. However, since traditional NMS is still needed in the frameworks, it is still difficult to recall the overlapped instances illustrated in Fig 2 (a). Re-scoring. In many detection frameworks [29, 24, 20, 21] a proposal box is bound to a ground truth as long as the overlap is larger than a given threshold, which usually leads to a many-to-one relation between proposals and groundtruth instances thus NMS is required to remove the duplicate proposals. Instead, if we redesign the loss function to encourage one-to-one relation, the NMS procedure may be eliminated to avoid miss detection. We name the method rescoring. Some of the previous works follow the idea. For example, in [26, 27], each ground-truth instance is associated strictly to one proposal box during training. However, in the architectures of [26, 27], due to lack of connections between proposals, the prediction may be ambiguous, because it is not sure for one proposal to determine whether the related instance has been predicted by another proposal. Actually, in [26, 27] NMS is still involved. RelationNet [19], instead, explicitly models the relations between proposals, which is supposed to overcome the limitations of [26, 27]. Using re-scoring, RelationNet obtains outstanding performance on COCO [22] dataset even without NMS. However, in a more crowded dataset CrowdHuman [32], we find RelationNet with re-scoring performs relatively poor (see Sec. 4 for details). It may be because on CrowdHuman dataset, proposals have to be much denser than those on COCO. As a result, the re-scoring network needs to generate different predictions from very close proposals (so their features and relations are also very similar, as shown in Fig. 2 (a)), which is infeasible for neural networks. There are other approaches on crowded detection, for example, part-based detectors [44, 38, 46, 3], which is mainly used in detecting special instances such as pedestrian. The discussions are omitted in this paper. In conclusion, based on the above analyses, we argue that object detection in the crowded scene may be fundamentally difficult, or at least nontrivial and complex for the mentioned existing proposal-based frameworks. The key issue lies in the basic paradigm of predicting only one instance for each proposal box. It inspires us to explore new instance prediction schemes, i.e. multiple instance prediction for each proposal.  

# 3. Our Approach: Multiple Instance Prediction 

Our approach is motivated by the observation: consider there are multiple objects heavily overlapped with each other, like the case in Fig. 2; if one proposal corresponds to any of the objects, it is very likely to overlap all the other objects. So, for such a proposal box, rather than predict a single object, why not predict them all? Formally, for each proposal box bi , the new scheme suggests predicting the correlated set of ground-truth instances G(bi) instead of a single object: G(bi) = {gj ∈ G|IoU(bi , gj ) ≥ θ} , (1) where G is the set of all the ground truth boxes and θ is a given threshold of intersection-over-union (IoU) ratio. Fig. 2 (b) visualizes the concept. Compared with the previous single-instance-prediction framework, we find our new scheme may greatly ease the learning in crowded scenes. As shown in Fig. 2 (b), all of the three proposal boxes are assigned to the same set of ground-truth instance – it is a feasible behavior since the three proposals actually share almost the same feature. While for the previous singleinstance-prediction paradigm (Fig. 2 (a)), each proposal has to produce distinguishing predictions, which might be intrinsically difficult. We introduce the details of our approach as follows:  Instance set prediction. For each proposal box bi, most of the modern proposal-based detection frameworks [29, 20, 21, 24, 13] employ a detection function to predict a pair (ci, li) to represent the associated instance, where ci is the class label with confidence and li is the relative coordinates. In our approach, to predict a set of instances, we introduce a simple extension – just by introducing K detection functions to generate a set of predictions P(bi): P(bi) = n(c (1) i , l (1) i ),(c (2) i , l (2) i ), . . . ,(c(K) i , l(K) i )o , (2) where K is a given constant standing for the maximum cardinality of G(bi) in the dataset (see Eq. 1). P(bi) can be simply implemented by introducing extra prediction branches in most of the existing detection frameworks [29, 20, 21, 13, 24], which is shown in Fig. 3 (a). Note that even though K is fixed for all proposals, the network could still predict some c(k) i to background class, representing that the k-th detection function does not predict instance for the proposal bi. EMD loss. We aim to design a loss L(bi) to minimize the gap between predictions P(bi) and ground-truth instances G(bi) corresponding to the proposal bi , which can be cataloged into the problem of set distance measurement. Similar problems have been discussed in some early object detection papers, such as [36, 7, 35]. Inspired by them, we design the following EMD loss to minimize the Earth Mover’s Distance between the two sets: L(bi) = min π∈ΠXKk=1 hLcls(c(k) i , gπk ) + Lreg(l(k) i , gπk )i (3) where π represents a certain permutation of (1, 2, . . . , K) whose k-th item is πk; gπk ∈ G(bi) is the πk-th groundtruth box; Lcls(·) and Lreg(·) are classification loss and box regression loss respectively, following the common definitions as [29, 24, 20, 21, 13]. Note that in Eq. 3, we assume |G(bi)| = K; if not, we add some “dummy” boxes (whose class label is regarded as background and without regression loss) to G(bi) until it is satisfied. Intuitively, the formulation in Eq. 3 implies to explore all possible one-toone matches between predictions and ground truths, thus finding the “best match” with the smallest loss. It is also worth noting that if K = 1, Eq. 3 becomes equivalent to the loss in traditional single-instance-prediction frameworks, implying that our EMD loss is a natural generalization to the commonly-used detection loss [29, 24, 20, 13]. Set NMS. In our approach, although each proposal is able to predict multiple associated instances, if na¨ıve NMS is still involved for post-processing it is impossible to detect objects effectively in crowded scenes. Fortunately, because of the EMD loss, instances predicted by one proposal are expected to be unique by definition. In other words, duplicates exist only between the predictions from different proposals, as illustrated in Fig. 2 (b). With this prior, we introduce a simple patch to na¨ıve NMS pipeline, named Set NMS – each time before one box suppressing another one in the NMS algorithm, we insert an additional test to check whether the two box come from the same proposal; if yes, we skip the suppression. Experiments in Sec. 4 also suggest that only when multiple-instance-prediction and Set NMS are used together can our approach achieve significant improvement in crowded detection. Refinement module. In our approach, each proposal is expected to generate a set of instances rather than a single one, which may suffer from increase in false positives since more predictions are generated. Although the failure cases are rarely observed in our experiments on real images, we introduce an optional refinement module in case of the risk, as shown in Fig. 3 (b). The module simply takes the predictions as input, combining them with proposal feature, then performs a second round of predicting. We expect the refinement module to correct the possible false predictions.    Discussion: relation to previous methods. Predicting multiple instance is not new. Double-person detector [37] models person pairs in the DPM [9] framework. In the deep learning era, some early detection systems [26, 27, 36, 7] also imply the high-level idea of multipleinstance-prediction, while the methods are not proposalbased. For example, MultiBox [7, 36] directly predicts all the instances in an image patch; YOLO v1/v2 [26, 27] generates multiple predictions for each cell (i.e. predicting all instances centered at a certain location). Special loss functions are also proposed in [7, 36, 26, 27] for set prediction, whose design purposes are similar to our EMD loss. The most related previous work to us is [35] which introduces LSTM to decode instance boxes in each grid of an image. Similar to our EMD loss, they use Hungarian Loss for multiple instance supervision. For post-processing, a box stitching method is employed to merge the predictions produced by adjacent grids. They mainly evaluated the method on head detection task, which shows some capability to predict crowded objects. However, since the method does not make use of proposals, it may have difficulty in detecting objects of various sizes/shapes, such as pedestrians or general objects. Moreover, the LSTM predictor is complex, which may be nontrivial to integrated in current state-ofthe-art detection frameworks [20, 21, 13] efficiently.   

## 3.1. Network Architecture 

Theoretically, our approach can be applied to most of the state-of-the-art proposal-based detectors, no matter onestage [24, 21, 28] or two-stage [29, 20, 13] frameworks. In this paper, we choose FPN [20] with RoIAlign [13] as a baseline detector to evaluate our method. In FPN, the Region Proposal Network (RPN) branch takes the responsibility for proposal generation, while the RCNN (or named RoI) branch is used to predict the instance corresponding to the RoI proposal. So, our method is attached to the latter branch. From Sec. 3, easy to see that there is only one extra hyper-parameter in our approach – K, the maximum cardinality of G(·) (refer to Eq. 2). In the rest of the paper, we let K = 2, which we find is satisfied for almost all the images and proposals in many detection datasets like CrowdHuman [32], COCO [22] and CityPersons [42]. Fig. 3 (a) illustrates the usage of our method in FPN (only RCNN branch is shown). Based on the original architecture, only slight modifications need to be made: just attach an additional instance prediction head to the tail. EMD loss is applied to the two predictions instead of the original loss. The refinement module is optional; if applied, we use the refined results as the final predictions.    

# 4. Experiment 

In this section, we evaluate our approach from different perspectives. Intuitively, a detection algorithm specially optimized for crowded scenes tends to recall more instances, however, often have the risk of increasing false positive predictions. Our benchmarks focus on both of the opposite aspects. Datasets. An ideal object detector for crowded scenes should be robust to instance distributions, i.e. not only effective for crowded detections, but also stable to detect single/less-crowded objects. We adopt three datasets – CrowdHuman [32], CityPersons [42] and COCO [22] for comprehensive evaluations on heavily, moderately and slightly overlapped situations respectively. Table 1 lists the “instance density” of each dataset. Since our proposed approach mainly aims to improve crowded detections. So, we perform most of the comparisons and ablations on CrowdHuman. Note that the experiment on uncrowded dataset like COCO is to verify whether our method does harm to isolated object detection, not for significant performance improvements. Evaluation metrics We mainly take the following three criteria for different purposes: • Averaged Precision (AP), which is the most popular metric for detection. AP reflects both the precision and recall ratios of the detection results. In our experiment, we empirically find AP is more sensitive to the recall scores, especially on crowded dataset like CrowdHuman. Larger AP indicates better performance. • $MR^{-2}$ [6], which is short for log-average Miss Rate on False Positive Per Image (FPPI) in [10 2, 100], is commonly used in pedestrian detection. $MR^{-2}$ is very sensitive to false positives (FPs), especially FPs with high confidences will significantly harm the $MR^{-2}$ ratio. Smaller $MR^{-2}$ indicates better performance. • Jaccard Index (JI) [24] is mainly used to evaluate the counting ability of a detector. Different from AP and $MR^{-2}$ which are defined on the prediction sequence with decreasing confidences, JI evaluates how much the prediction set overlaps the ground truths. Usually, the prediction set can be generated by introducing a confidence score threshold. In this paper, for each evaluation entry, we report the best JI score by exploring all possible confidence thresholds. We use the official SDK of CrowdHuman [32] for JI calculation. Larger JI indicates better performance. Detailed Settings. Unless otherwise specified, we use standard ResNet-50 [15] pre-trained on ImageNet [31] as the backbone network for all the experiments. The baseline detection framework is FPN [20], while using RoIAlign [13] instead of original RoIPooling. As for anchor settings, we use the same anchor scales as [20], while the aspect ratios are set to H : W = {1 : 1, 2 : 1, 3 : 1} for CrowdHuman and CityPersons, and {2 : 1, 1 : 1, 1 : 2} for COCO.For training, we use the same protocol as in [20]. The batch size is 16, split to 8 GPUs. Each training runs for 30 epochs. During training, the sampling ratio of positive to negative proposals for RoI branch is 1 : 1 for CrowdHuman and 1 : 3 for CityPersons and COCO. Multi-scale training and test are not applied; instead, the short edge of each image is resized to 800 pixels for both training and test. All box overlap IoU thresholds (e.g. θ in Eq. 1, NMS thresholds, and those in calculating evaluation metrics) are set to 0.5 by default. For our method, we use K = 2 (see Eq. 2). The refinement module in Fig. 3 is enabled by default.  

## 4.1. Experiment on CrowdHuman 

CrowdHuman [32] contains 15,000, 4,370 and 5,000 images for training, validation and test respectively. For fair comparison, we retrain most of the involved models with our own implementation under the same settings. Results are mainly evaluated on the validation set, using full-body benchmark in [32]. Main results and ablation study. Table 2 shows the ablation experiments of the proposed methods in Sec. 3, including multiple instance prediction with EMD loss, set NMS and refinement module. The baseline is FPN [20] using NMS (IoU threshold is 0.5) for post-processing. It is clear that our methods consistently improve the performances in all criteria. Especially, even without refinement module our method still obtains 4.5% improvements in AP and 2.2% in JI, suggesting that more instances may correctly detected; more importantly, we find the $MR^{-2}$ ratio also improves, indicating that our model does not introduce more false predictions. The refinement module affects little on AP and JI, while further boosting $MR^{-2}$ by ∼0.8%, suggesting that the module mainly reduces false positives as we expected.    Comparisons with various NMS strategies. In Fig. 1, since some instances are mistakenly suppressed by NMS, one possible hypothesis is that the predictions may be improved by using different NMS strategies. Table 3 explores some variants. For na¨ıve NMS, compared with the default setting (0.5), slightly enlarging the IoU threshold (from 0.5 to 0.6) may help to recall more instances, so AP increases; however, the $MR^{-2}$ index becomes much worse (from 42% to 45.4%), indicating that more false positives are introduced. Soft-NMS [1] can boost AP score, but no improvements are obtained in $MR^{-2}$ and JI. In contrast, our method achieves the best scores in all the three metrics even without refinement module. Comparisons with previous works. To our knowledge, very few previous works on crowded detection report their results on CrowdHuman. To compare, we benchmark two methods – GossipNet [18] and RelationNet [19] – which are representative works categorized into advanced NMS and re-scoring approaches respectively (see Sec. 2 for the analyses). For GossipNet, we use the open-source implementation to benchmark1 . And for RelationNet, we re-implement the re-scoring version2 . All methods use FPN [20] as the base detector with the same training settings. Table 4 lists the comparison results. Surprisingly, both RelationNet and GossipNet suffer from significant drop in AP and $MR^{-2}$ . Further analyses indicate that the two methods have better recall ratio than baseline NMS for crowded objects (see Table 5), however, tend to introduce too many false positive predictions. Though it is still too early to claim [19, 18] do not work on CrowdHuman (we have not fully explored the hyper-parameters), at least the two methods are nontrivial for tuning. In contrast, our method is not only effective, but also very simple, as it has almost no additional hyper-parameters. Table 4 also compares a recent work AdaptiveNMS [23], which is an enhanced NMS strategy for crowded detection. In [23], CrowdHuman results based on FPN are reported. Note that since the baseline are not aligned, we cannot make the direct comparison with our results. From the numbers, we find that our method can achieve significant improve-ment from a stronger baseline (especially in AP), in addition, the pipeline is much simpler. Table 4 also evaluate our method on the Cascade R-CNN [2] framework. We add the EMD loss and Set NMS into the last stage of Cascade R-CNN. The results show our method can still boost the performance of Cascade R-CNN significantly on crowded datasets like CrowdHuman.  Analysis on recalls. To further understand the effectiveness of our method on crowded objects, we compare the recalls of different approaches for both crowded and uncrowded instances respectively. Results are shown in Table. 5. Note that recall relates to the confidence score threshold. For fair comparison, we use the thresholds corresponding to the best JI index for each entry respectively. From the table we find that for FPN baseline/Soft-NMS, recall of crowded objects is much lower than that of uncrowded objects, implying the difficulty of crowded detection. In contrast, our method greatly improves the recall ratio of the crowded instances (from 54.4% to 63.3%, by 8.9%), in addition, uncrowded recall is also slightly improved.   

## 4.2. Experiments on CityPersons 

CityPersons [42] is one of the widely used benchmarks for pedestrian detection. The dataset contains 5, 000 images (2, 975 for training, 500 for validation, and 1, 525 for testing, respectively). Each image is with a size of 1024 × 2048. Following the common practice in previous works, all of the object detectors are trained on the training (reasonable) subset and tested on the validation (reasonable) subset with the enlarged resolution by 1.3× compared to the original one, which is slightly different from the settings we used for CrowdHuman [32] and COCO [22]. To obtain a better baseline, we follow the strategy proposed in [3], namely evolving ground-truths into proposals by jittering.Other hyper-parameters remains the same as that in Sec. 4.    Qualitative results. Table 7 compares our method with FPN baselines with na¨ıve NMS and Soft-NMS respectively. Our approach improves AP and $MR^{-2}$ by 0.9% and 1.0% respectively over the NMS baseline, indicating the effectiveness our method. Table 7 also lists some other stateof-the-art results on CityPersons. Though it may be unfair for direct comparisons due to different hyper-parameter settings, however, at least it implies our method achieves significant gains over a relatively strong baseline.  Table 6 further analyzes the recalls of different methods. Similar to those in CrowdHuman (refer to Table 6), our method mainly significantly boosts the recall on crowded objects – from 64 increased to 96 out of a total of 108 instances in the validation set. The comparison further indicates our approach is very effective to deal with crowded scenes again.   

## 4.3. Experiments on COCO 

According to Table 1, the crowdedness of COCO [22] is very low, which is out of our design purpose. So, we do not expect a significant performance gain on COCO. Instead, the purpose of introducing COCO is to verify: 1) whether our method generalizes well to multi-class detection problems; 2) whether the proposed approach is robust to different crowdedness, especially to isolated instances.   Following the common practice of [20, 21], we use a subset of 5000 images in the original validation set (named minival) for validation, while using the remaining images in the original training and validation set for training. Table 8 shows the comparisons with FPN and FPN+Soft-NMS baselines. Moderate improvements are obtained, e.g. 1.0% better than na¨ıve NMS and 0.5% better than Soft-NMS in AP. Interestingly, large objects achieve the most significant improvement (see APL in Table 8), which may be because larger objects are more likely to overlap. The experiment suggests our method is not only very effective on crowded scenes, but also able to deal with multiple classes and isolated instances without performance drop.   

# 5. Conclusion 

In this paper, we propose a very simple yet effective proposal-based object detector, specially designed for crowded instance detection. The method makes use of the concept of multiple instance prediction, introducing new techniques such as EMD loss, Set NMS and refinement module. Our approach is not only effective, but also flexible to cooperate with most state-of-the-art proposal-based detection frameworks; in addition, also generalizes well to less crowded scenarios.