[FPN（feature pyramid networks）算法讲解](https://blog.csdn.net/u014380165/article/details/72890275)
[论文 - Feature Pyramid Networks for Object Detection (FPN)](https://xmfbit.github.io/2018/04/02/paper-fpn/)

FPN主要解决的是物体检测中的多尺度问题，通过简单的网络连接改变，在基本不增加原有模型计算量情况下，大幅度提升了小物体检测的性能。

# 论文概述

作者提出的多尺度的目标检测算法：FPN。
（1）原来的检测只采用顶层特征做预测。
（2）但我们知道低层特征语义信息少，但是目标位置准确；高层特征语义信息丰富，但是目标位置粗略。
（3）有些算法采用多尺度融合的方式，但是一般是采用融合后的特征做预测。
本方法不同的是预测在不同特征层独立进行。

# 论文详解

# 论文背景

## 传统解决思路：
（1）多尺度训练和测试，又称图像金字塔。
（2）特征分层。每层分别预测对应的Scale的分辨率的结果。SSD采用这样的思想，这个方法问题在于直接强行让不同层学习同样的语义信息。而对于神经网络而言，不同深度对应着不同层次的语义特征，浅层多是细节特征，深度是语义特征。

## 多尺度物体检测面临的挑战
1. 如何学习具有强语义信息的多尺度特征表示？
2. 如何设计通用的特征表示解决物体检测中的多个子问题
3. 如何高效计算多尺度特征表示。

本文针对这些问题，提出了特征金字塔网络FPN，如图1(d)所示，网络直接在原来的单网络上做修改，每个分辨率的feature map引入后一分辨率缩放两倍的feature map做element-wise相加的操作。通过这样的连接，每一层预测所用的feature map都融合了不同分辨率、不同语义强度的特征，融合的不同分辨率的feature map分别做对应分辨率大小的物体检测。这样保证了每一层都有合适的分辨率以及强语义特征。同时，由于此方法只是在原网络基础上加上了额外的跨层连接，在实际应用中几乎不增加额外的时间和计算量。作者接下来实验了将FPN应用在Faster RCNN上的性能，在COCO上达到了state-of-the-art的单模型精度。

具体而言，FPN分别在RPN和Fast RCNN两步中起到作用。其中RPN和Fast RCNN分别关注的是召回率和正检率，在这里对比的指标分别为Average Recall(AR)和Average Precision(AP)。分别对比了不同尺度物体检测情况，小中大物体分别用s,m,l表示。

与RPN一样，FPN每层feature map加入3*3的卷积及两个相邻的1*1卷积分别做分类和回归的预测。在RPN中，实验对比了FPN不同层feature map卷积参数共享与否，发现共享仍然能达到很好性能，说明特征金字塔使得不同层学到了相同层次的语义特征。RPN网络的实验结果为：

这里FPN对比原来取自conv4和conv5的RPN网络(a)(b)，召回率得到了大幅度提升，尤其在中物体和小物体上(c)。另外，作者做了变量对比实验，比如只保留横向连接(d)，即特征分层网络，性能仅与原RPN差不多，原因就在于不同层之间的语义特征差距较大。另外，试验了砍掉横向连接，只保留自上而下放大feature map做预测结果(e)，以及只用最终得到的feature map层(f)，均比完整的FPN网络小物体检测AR低10个点左右。说明金字塔特征表示与横向连接都起了很大作用。



实验Fast RCNN时，需要固定FPN+RPN提取的proposal结果。在Fast RCNN里，FPN主要应用于选择提取哪一层的feature map来做ROI pooling。假设特征金字塔结果对应到图像金字塔结果。定义不同feature map集合为{P2, P3, P4, P5}，对于输入网络的原图上w*h的ROI，选择的feature map为Pk，其中（224为ImageNet输入图像大小）：